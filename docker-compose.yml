version: "3.7"

name: bar

services:
  gateway:
    container_name: bar.gateway
    build:
      context: ./gateway
      dockerfile: Dockerfile
    networks:
      - bar_network
    ports:
      - 5010:80
    volumes:
      - ~/.vsdbg:/remote_debugger/
    labels:
      - SERVICE_CHECK_HTTP=/health
      - SERVICE_CHECK_INTERVAL=60s
      - SERVICE_NAME=gateway
    depends_on:
      - grafana

  brand:
    build:
      context: ./brand.service
      dockerfile: Dockerfile
    networks:
      - bar_network
    ports:
      - 5011:80
    labels:
      - SERVICE_CHECK_HTTP=/health
      - SERVICE_CHECK_INTERVAL=60s
      - SERVICE_NAME=brand.service
    volumes:
      - ~/.vsdbg:/remote_debugger/
    depends_on:
      - postgres
      - grafana

  consul:
    container_name: bar.consul
    image: consul:1.15.4
    environment:
      - CONSUL_BIND_INTERFACE=eth0
    ports:
      - 8500:8500
    networks:
      - bar_network

  consul-registrator:
    container_name: bar.consul.registrator
    image: gliderlabs/registrator:master
    command: "-explicit=true -internal=true consul://consul:8500"
    volumes:
      - /var/run/docker.sock:/tmp/docker.sock:ro
    networks:
      - bar_network
    depends_on:
      - consul

  postgres:
    container_name: bar.postgres
    image: polaris/postgres:local
    build:
      context: ./postgres
      dockerfile: Dockerfile
    networks:
      - bar_network
    ports:
      - 5432:5432
    environment:
      - POSTGRES_DB=default_db
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - ./postgres/init.sh:/docker-entrypoint-initdb.d/init.sh
      - postgres_db:/var/lib/postgresql/data

  collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: collector
    command: [ "--config=/etc/collector.yaml" ]
    networks:
      - bar_network
    ports:
      - 8888:8888 
      - 8889:8889 
      - 13133:13133
      - 4317:4317
    volumes:
      - ./otel/otel-collector-config.yml:/etc/collector.yaml
    depends_on:
      - tempo

  tempo:
    image: grafana/tempo:latest
    container_name: tempo
    command: [ "-config.file=/etc/tempo.yaml" ]
    networks:
      - bar_network
    volumes:
      - ./tempo/tempo.yml:/etc/tempo.yaml

  grafana:
    image: grafana/grafana:10.0.2
    container_name: grafana
    networks:
      - bar_network
    ports:
      - 3000:3000
    volumes:
      - ./grafana/grafana-datasources.yml:/etc/grafana/provisioning/datasources/datasources.yaml
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
    depends_on:
      - collector
      - tempo

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    networks:
      - bar_network
    ports:
      - 9090:9090
    command: "--config.file=/etc/prometheus/prometheus.yaml"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yaml:ro
      - prometheus-data:/prometheus

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.0     
    container_name: cadvisor
    networks:
      - bar_network
    ports:
      - 8080:8080
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    devices:
      - /dev/kmsg
    privileged: true

  node_exporter:
    image: quay.io/prometheus/node-exporter:v1.5.0
    container_name: node_exporter
    command: "--path.rootfs=/host"
    networks:
      - bar_network
    pid: host
    volumes:
      - /:/host:ro,rslave

  elasticsearch:
    image: elasticsearch:8.12.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    networks:
      - bar_network
    ports:
      - 9200:9200
      - 9300:9300
    volumes:
      - elasticsearch:/usr/share/elasticsearch/data
    deploy:
      resources:
        limits:
          memory: 4G

  kibana:
    image: kibana:8.12.0
    ports:
      - 5601:5601
    networks:
      - bar_network
    depends_on:
      - elasticsearch

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    networks:
      - bar_network
    ports:
      - 80:80      

######################## KAFKA

#   zookeeper:
#     image: 'bitnami/zookeeper:latest'
#     restart: "no"
#     networks:
#       - bar_network
#     ports:
#       - '2181:2181'
#     environment:
#       - ALLOW_ANONYMOUS_LOGIN=yes
#     container_name: zookeeper

# #Kafka Service
# #Image Tag: bitnami/kafka:2.7.0

#   kafka1:
#     image: 'bitnami/kafka:latest'
#     restart: "no"
#     networks:
#       - bar_network
#     ports:
#       - '9092:9092'
#       - '29092:29092'
#     environment:
#       - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
#       - KAFKA_CFG_LISTENERS=INTERNAL://:29092,EXTERNAL://:9092
#       - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka1:29092,EXTERNAL://localhost:9092
#       - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
#       - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL
#       - KAFKA_MESSAGE_MAX_BYTES=10000000
#       - KAFKA_SOCKET_REQUEST_MAX_BYTES=100001200
#       - KAFKA_DEFAULT_REPLICATION_FACTOR=2
#       - KAFKA_NUM_PARTITIONS=2
#       - ALLOW_PLAINTEXT_LISTENER=yes
#     container_name: kafka-broker1
#     depends_on:
#       - "zookeeper"
      
#   kafka2:
#     image: 'bitnami/kafka:latest'
#     restart: "no"
#     networks:
#       - bar_network
#     ports:
#       - '9093:9093'
#       - '29093:29093'
#     environment:
#       - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
#       - KAFKA_CFG_LISTENERS=INTERNAL://:29093,EXTERNAL://:9093
#       - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka2:29093,EXTERNAL://localhost:9093
#       - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
#       - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL
#       - KAFKA_MESSAGE_MAX_BYTES=10000000
#       - KAFKA_SOCKET_REQUEST_MAX_BYTES=100001200
#       - KAFKA_DEFAULT_REPLICATION_FACTOR=2
#       - KAFKA_NUM_PARTITIONS=2
#       - ALLOW_PLAINTEXT_LISTENER=yes
#     container_name: kafka-broker2
#     depends_on:
#       - "zookeeper"
    
#   kafka3:
#     image: 'bitnami/kafka:latest'
#     restart: "no"
#     networks:
#       - bar_network
#     ports:
#       - '9094:9094'
#       - '29094:29094'
#     environment:
#       - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
#       - KAFKA_CFG_LISTENERS=INTERNAL://:29094,EXTERNAL://:9094
#       - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka3:29094,EXTERNAL://localhost:9094
#       - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
#       - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL
#       - KAFKA_MESSAGE_MAX_BYTES=10000000
#       - KAFKA_SOCKET_REQUEST_MAX_BYTES=100001200
#       - KAFKA_DEFAULT_REPLICATION_FACTOR=2
#       - KAFKA_NUM_PARTITIONS=2
#       - ALLOW_PLAINTEXT_LISTENER=yes
#     container_name: kafka-broker3
#     depends_on:
#       - "zookeeper"
      
# #KafDrop UI for management
# #Image Tag: obsidiandynamics/kafdrop:3.27.0

#   kafdrop:
#     image: 'obsidiandynamics/kafdrop:latest'
#     restart: "no"
#     networks:
#       - bar_network
#     ports:
#       - 9001:9000
#     environment:
#       - KAFKA_BROKERCONNECT=kafka1:29092,kafka2:29093,kafka3:29094
#       - JVM_OPTS=-Xms32M -Xmx64M
#       - SERVER_SERVLET_CONTEXTPATH=/
#     container_name: kafdrop
#     depends_on:
#       - "kafka1"
#       - "kafka2"
#       - "kafka3"
      
volumes:
  postgres_db:
  prometheus-data:
    driver: local
  elasticsearch:

networks:
  bar_network:

